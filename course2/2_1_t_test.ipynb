{"cells":[{"cell_type":"code","metadata":{"tags":[],"cell_id":"00000-d1d69d90-57d1-41ab-8816-3273e92f9d9a","deepnote_cell_type":"code"},"source":"# Start writing code here...","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## T-Test\n\nA t-test is a type of inferential statistic used to determine if there is a significant difference between the means of two groups, which may be related in certain features. The t-test is one of many tests used for the purpose of hypothesis testing in statistics.\nIn this tutorial, you will discover how to implement the Student’s t-test statistical hypothesis test from scratch in Python.\n\n","metadata":{"tags":[],"cell_id":"00002-e0853f85-739a-4850-ab17-d1d07fdd401c","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"# Start by importing numpy\nimport numpy as np\n# And import stats from scipy\nfrom scipy import stats\n\n# First we generate some data\n# Define 20 data points for each group\nN = 20\n\n# Let’s assume that our two data samples are stored in the variables data1 and data2.\n# data1 is a Gaussian distributed data with size N and the mean would be 2\ndata1 = np.random.randn(N) + 2\n# data2 is the same except with mean 0, both with variance 1\ndata2 = np.random.randn(N)\n\n# To compute the standard error, which we can compute manually, we first calculate the sample standard deviations\nvar_a = a.var(ddof = 1)\nvar_b = b.var(ddof = 1)\n\n# Calculate pooled standard deviation\n\ns = np.sqrt((var_a + var_b) / 2)\n\n# Of course, there is a convenient function sem() in SciPy that helps calculate the standard error directly.\n\n# We can now calculate the t-statistics\n\nt = (a.mean() - b.mean()) / (s * np.sqrt(2.0/N))\n\n# Calculate the degree of freedom\n# The number of degrees of freedom for the test is calculated as the sum of the observations in both samples, minus two\ndf = 2 * N - 2\n\n# The critical value can be calculated using the percent point function (PPF) for a given significance level, such as 0.05\n\n# and the p-value can be calculated using the cumulative distribution function on the t-distribution, again in SciPy.\np = 1 - stats.t.cdf(t, df = df)\n\nprint(t, 2*p)","metadata":{"tags":[],"cell_id":"00003-707ed0a0-c57a-488e-bac7-735362ddc733","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"tags":[],"cell_id":"00003-b1ca8fe9-5c7d-41f5-b5fa-249789c68ad1","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Note that the t-test in Bayesian statistics is more flexible, meaning more lightweight with formula but simulation-oriented.\nFor more advanced type of t-test in statistical analysis, I recommend you to go to https://machinelearningmastery.com/how-to-code-the-students-t-test-from-scratch-in-python/ and see some examples.\n\nIn this lecture we have gone through an examples about t-test in comparing different group of data. It is a critical concept for statistical analsysis. We will play around with Bayesian estimation techniques to compare group differences in the second and third weeks of lectures. By for now!","metadata":{"tags":[],"cell_id":"00004-fc4fd63d-0a09-4573-9fd4-ff745e1c8a77","deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":2,"metadata":{"orig_nbformat":2,"deepnote_notebook_id":"1a07794a-2d71-4785-ae55-2c52814a5efd","deepnote_execution_queue":[]}}